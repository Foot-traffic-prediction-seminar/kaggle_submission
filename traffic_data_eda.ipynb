{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 86470,
          "databundleVersionId": 9985974,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "notebook_test",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "OQNL06l0AUhH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "ftwue_path = kagglehub.competition_download('ftwue')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "M3HVHI0_AUhK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Foot Traffic in WÃ¼rzburg"
      ],
      "metadata": {
        "id": "hkd8A8GZAUhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Short Kaggle Info"
      ],
      "metadata": {
        "id": "d6j1ckR3AUhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T16:49:26.47156Z",
          "iopub.execute_input": "2025-01-17T16:49:26.472059Z",
          "iopub.status.idle": "2025-01-17T16:49:26.478665Z",
          "shell.execute_reply.started": "2025-01-17T16:49:26.472014Z",
          "shell.execute_reply": "2025-01-17T16:49:26.477277Z"
        },
        "id": "1W7M4_KbAUhO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "Q7bQpwC0AUhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "id": "2h1BNrIvAUhP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv(f'{ftwue_path}/sample_submission.csv')\n",
        "sample_submission"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:00:47.986077Z",
          "iopub.execute_input": "2025-01-17T17:00:47.986534Z",
          "iopub.status.idle": "2025-01-17T17:00:48.005608Z",
          "shell.execute_reply.started": "2025-01-17T17:00:47.9865Z",
          "shell.execute_reply": "2025-01-17T17:00:48.00438Z"
        },
        "id": "uajZgsHWAUhP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f'{ftwue_path}/train.csv')\n",
        "train_df.head(2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:00:57.00818Z",
          "iopub.execute_input": "2025-01-17T17:00:57.00853Z",
          "iopub.status.idle": "2025-01-17T17:00:57.251415Z",
          "shell.execute_reply.started": "2025-01-17T17:00:57.008504Z",
          "shell.execute_reply": "2025-01-17T17:00:57.250246Z"
        },
        "id": "q_ASsx2gAUhP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# View initial columns\n",
        "train_df.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:10:53.939207Z",
          "iopub.execute_input": "2025-01-17T17:10:53.939605Z",
          "iopub.status.idle": "2025-01-17T17:10:53.983898Z",
          "shell.execute_reply.started": "2025-01-17T17:10:53.939579Z",
          "shell.execute_reply": "2025-01-17T17:10:53.982761Z"
        },
        "id": "7m9m50-kAUhQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(f'{ftwue_path}/test.csv')\n",
        "test_df.head(2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:01:02.76209Z",
          "iopub.execute_input": "2025-01-17T17:01:02.762567Z",
          "iopub.status.idle": "2025-01-17T17:01:02.783266Z",
          "shell.execute_reply.started": "2025-01-17T17:01:02.762535Z",
          "shell.execute_reply": "2025-01-17T17:01:02.782005Z"
        },
        "id": "SvdoM5Z9AUhQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# View initial columns\n",
        "test_df.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:11:42.286207Z",
          "iopub.execute_input": "2025-01-17T17:11:42.286567Z",
          "iopub.status.idle": "2025-01-17T17:11:42.298953Z",
          "shell.execute_reply.started": "2025-01-17T17:11:42.286542Z",
          "shell.execute_reply": "2025-01-17T17:11:42.297545Z"
        },
        "id": "AwG5d2TVAUhQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "json_locations = open(f'{ftwue_path}/counterGeoLocations.json', 'r')\n",
        "print(json_locations.read())\n",
        "# json_locations.close()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:01:06.986709Z",
          "iopub.execute_input": "2025-01-17T17:01:06.98703Z",
          "iopub.status.idle": "2025-01-17T17:01:06.994059Z",
          "shell.execute_reply.started": "2025-01-17T17:01:06.987006Z",
          "shell.execute_reply": "2025-01-17T17:01:06.992502Z"
        },
        "id": "oHVF3copAUhR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Setting the features and target variables"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y_2neVgQAUhR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_df[\"n_pedestrians\"]\n",
        "X = X = train_df.drop(columns=[\"n_pedestrians\"])\n",
        "\n",
        "print(X.shape)  # (82821, 12) -> X features\n",
        "print(y.shape)  # (82821,) -> y target variable (demand)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:02:43.42826Z",
          "iopub.execute_input": "2025-01-17T17:02:43.428613Z",
          "iopub.status.idle": "2025-01-17T17:02:43.449455Z",
          "shell.execute_reply.started": "2025-01-17T17:02:43.428588Z",
          "shell.execute_reply": "2025-01-17T17:02:43.448225Z"
        },
        "id": "YDwGdHA-AUhR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Add feature: Season\n",
        "\n",
        "X['date'] = pd.to_datetime(X['date'])\n",
        "\n",
        "# New columns: Extract the missing date features (month and year)\n",
        "X['month'] = X['date'].dt.month\n",
        "X['year'] = X['date'].dt.year\n",
        "\n",
        "# Map months to seasons\n",
        "X['season'] = X['month'].apply(lambda x:\n",
        "    'winter' if x in [12, 1, 2] else\n",
        "    'spring' if x in [3, 4, 5] else\n",
        "    'summer' if x in [6, 7, 8] else\n",
        "    'autumn'\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:09:14.587431Z",
          "iopub.execute_input": "2025-01-17T17:09:14.587877Z",
          "iopub.status.idle": "2025-01-17T17:09:14.638392Z",
          "shell.execute_reply.started": "2025-01-17T17:09:14.587848Z",
          "shell.execute_reply": "2025-01-17T17:09:14.637264Z"
        },
        "id": "MqOsaoZsAUhR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one-hot encodings\n",
        "\n",
        "X = pd.get_dummies(X, columns=[\"year\",\"day\",\"month\",\"streetname\",\"season\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "hsCGGme3AUhS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# View columns\n",
        "X.columns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:12:55.992398Z",
          "iopub.execute_input": "2025-01-17T17:12:55.992829Z",
          "iopub.status.idle": "2025-01-17T17:12:56.001433Z",
          "shell.execute_reply.started": "2025-01-17T17:12:55.992797Z",
          "shell.execute_reply": "2025-01-17T17:12:55.999102Z"
        },
        "id": "I8T4DZ6aAUhS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensuring data coverage by street**"
      ],
      "metadata": {
        "id": "6z7Z7LosAUhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_df.copy()\n",
        "\n",
        "# Dictionary to store the full time series DataFrame for each streetname combination\n",
        "street_time_series_dict = {}\n",
        "\n",
        "# Iterate over each group and store the full DataFrame as the time series\n",
        "for streetname, group in data.groupby('streetname'):  # Group only by 'streetname', no tuple\n",
        "    # Sort the group by 'date' to ensure chronological order\n",
        "    group = group.sort_values(by='date')\n",
        "\n",
        "    # Include both 'n_pedestrians_towards' and 'n_pedestrians_away' in the time series\n",
        "    time_series_df = group[['date', 'n_pedestrians_towards', 'n_pedestrians_away']].copy()\n",
        "\n",
        "    # Add a total pedestrians column\n",
        "    time_series_df['total_pedestrians'] = group['n_pedestrians_towards'] + group['n_pedestrians_away']\n",
        "\n",
        "    # Store the full time series DataFrame for this streetname\n",
        "    street_time_series_dict[streetname] = time_series_df\n",
        "\n",
        "# Display an example of a time series for a specific streetname (optional)\n",
        "for key, time_series in street_time_series_dict.items():\n",
        "    print(f\"Time series for {key}:\\n\", time_series.head())\n",
        "    # break  # Uncomment if you only want to see one street's time series"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:35:07.717836Z",
          "iopub.execute_input": "2025-01-17T17:35:07.718233Z",
          "iopub.status.idle": "2025-01-17T17:35:07.820993Z",
          "shell.execute_reply.started": "2025-01-17T17:35:07.718202Z",
          "shell.execute_reply": "2025-01-17T17:35:07.819711Z"
        },
        "id": "YlBiw_f9AUhS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Loop through each street and plot the total pedestrians time series\n",
        "for streetname, time_series in street_time_series_dict.items():\n",
        "    plt.figure(figsize=(10, 6))  # Create a new figure for each street\n",
        "\n",
        "    # Plot total pedestrians\n",
        "    plt.plot(time_series['date'], time_series['total_pedestrians'], label=f'{streetname} - Total', color='green')\n",
        "\n",
        "    # Add title and labels\n",
        "    plt.title(f'Total Pedestrians for {streetname}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Total Number of Pedestrians')\n",
        "\n",
        "    # Format the x-axis to show quarterly ticks (every 3 months)\n",
        "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(bymonthday=1, interval=3))  # Every 3 months\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))  # Format as Year-Month\n",
        "\n",
        "    # Rotate x-axis labels for better readability\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Add a legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Adjust layout to prevent overlap\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:47:10.396731Z",
          "iopub.execute_input": "2025-01-17T17:47:10.397199Z",
          "iopub.status.idle": "2025-01-17T17:47:12.651558Z",
          "shell.execute_reply.started": "2025-01-17T17:47:10.397157Z",
          "shell.execute_reply": "2025-01-17T17:47:12.650255Z"
        },
        "id": "cmfek_ENAUhS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Using a standard scaler only on continuous variables\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X contains your features and y your target\n",
        "\n",
        "# Separate the date column from X for train-test splitting\n",
        "date_column = X['date']  # Keep date separately for reference (if you want to use it later)\n",
        "\n",
        "# Perform train-test split without 'date' column (already done previously)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X.drop(columns=['date']), y, train_size=0.75, shuffle=True\n",
        ")\n",
        "\n",
        "# Standardization (scaling) for continuous features\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[['n_pedestrians_towards', 'n_pedestrians_away', 'temperature']])  # Use continuous columns\n",
        "\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[['n_pedestrians_towards', 'n_pedestrians_away', 'temperature']] = scaler.transform(X_train[['n_pedestrians_towards', 'n_pedestrians_away', 'temperature']])\n",
        "X_test_scaled[['n_pedestrians_towards', 'n_pedestrians_away', 'temperature']] = scaler.transform(X_test[['n_pedestrians_towards', 'n_pedestrians_away', 'temperature']])\n",
        "\n",
        "# Reset the indices of the train and test sets to ensure alignment\n",
        "X_train_scaled.reset_index(drop=True, inplace=True)\n",
        "X_test_scaled.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Concatenate date, scaled features X and scaled target y for train and test sets\n",
        "train_data = pd.concat([date_column.loc[X_train.index].reset_index(drop=True), X_train_scaled, y_train], axis=1)\n",
        "test_data = pd.concat([date_column.loc[X_test.index].reset_index(drop=True), X_test_scaled, y_test], axis=1)\n",
        "\n",
        "# Print the info of the train_data\n",
        "train_data.info()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T17:56:12.394728Z",
          "iopub.execute_input": "2025-01-17T17:56:12.395196Z",
          "iopub.status.idle": "2025-01-17T17:56:12.545975Z",
          "shell.execute_reply.started": "2025-01-17T17:56:12.395161Z",
          "shell.execute_reply": "2025-01-17T17:56:12.544619Z"
        },
        "id": "gCgZctj3AUhT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aggregation by month and year for seasonal analysis"
      ],
      "metadata": {
        "id": "spiZ8ZysAUhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed, aggregate by 'year-month' for both train and test sets\n",
        "train_data['year_month'] = train_data['date'].dt.to_period('M').dt.to_timestamp()\n",
        "test_data['year_month'] = test_data['date'].dt.to_period('M').dt.to_timestamp()\n",
        "\n",
        "# Group by year-month and aggregate the 'demand' values\n",
        "train_df = train_data.groupby('year_month').agg({'demand': 'sum'}).reset_index()\n",
        "test_df = test_data.groupby('year_month').agg({'demand': 'sum'}).reset_index()\n",
        "\n",
        "# Count the number of unique year-month values in the train set\n",
        "print(train_df['year_month'].count())  # This will show the number of months in the training data\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "FSodsNsDAUhT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run some sample models"
      ],
      "metadata": {
        "id": "lYtgCcy9AUhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "3OqFRKNLAUhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.columns)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-17T18:00:30.8093Z",
          "iopub.execute_input": "2025-01-17T18:00:30.809664Z",
          "iopub.status.idle": "2025-01-17T18:00:30.816008Z",
          "shell.execute_reply.started": "2025-01-17T18:00:30.809639Z",
          "shell.execute_reply": "2025-01-17T18:00:30.814692Z"
        },
        "id": "lQtnA9mGAUhT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}